{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yaml\n",
    "import sys\n",
    "from audit import exp_one_acc, exp_all_acc, exp_worst_eps, exp_estimated_epsilon, exp_all_avg_acc, exp_all_group_avg_acc\n",
    "from visual import *\n",
    "from util import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(dataset_name, model_name):\n",
    "    configs = f\"configs/{dataset_name}/{dataset_name}_regular.yaml\"\n",
    "    if model_name == \"LR\" and dataset_name != \"mnist\":\n",
    "        configs = f\"configs/tabular/{dataset_name}/{dataset_name}_regular.yaml\"\n",
    "\n",
    "    with open(configs, \"rb\") as f:\n",
    "        configs = yaml.load(f, Loader=yaml.Loader)\n",
    "    return configs\n",
    "\n",
    "\n",
    "## get data\n",
    "def get_one_seed(dataset_name, model_name, method, epsilon, other, seed, configs):\n",
    "    subdata_dir = f'{configs[\"run\"][\"log_dir\"]}{dataset_name}.pkl'\n",
    "    log_dir = f'{configs[\"run\"][\"log_dir\"]}{model_name}/{method}/eps{epsilon}{seed}'\n",
    "    directories = {\n",
    "        \"log_dir\": log_dir,\n",
    "        \"report_dir\": f\"{log_dir}/report\",\n",
    "        \"signal_dir\": f\"{log_dir}/signals\",\n",
    "    }\n",
    "    num_group = configs[\"train\"][\"num_groups\"]\n",
    "\n",
    "    path = subdata_dir\n",
    "    if num_group == 2:\n",
    "        path = f\"data/tabular/{dataset_name}.pkl\"\n",
    "    elif num_group == 5:\n",
    "        path = f\"data/{dataset_name}.pkl\"\n",
    "    with open(path, \"rb\") as file:\n",
    "        dataset = pickle.load(file)\n",
    "\n",
    "    path = directories[\"report_dir\"]\n",
    "    memberships = np.load(f\"{path}/memberships.npy\")\n",
    "    loss_scores = np.load(f\"{path}/loss_scores.npy\")\n",
    "\n",
    "\n",
    "    alooa_adv_group, ga_adv_group, gba_adv_group = [], [], []\n",
    "    alooa_acc = exp_all_acc(f\"{directories['report_dir']}/loss\", loss_scores, memberships, dataset, num_group)\n",
    "    alooa_adv = [[2*value-1 for value in group] for group in alooa_acc]\n",
    "    alooa_adv_group = [np.mean([value for value in group]) for group in alooa_adv]\n",
    "\n",
    "    if other:\n",
    "        ga_acc = exp_all_avg_acc(f\"{directories['report_dir']}/loss\", loss_scores, memberships, dataset, num_group)\n",
    "        ga_adv = [[2*value-1 for value in group] for group in ga_acc]\n",
    "        ga_adv_group = [np.mean([value for value in group]) for group in ga_adv]\n",
    "\n",
    "        gba_acc = exp_all_group_avg_acc(f\"{directories['report_dir']}/loss\", loss_scores, memberships, dataset, num_group)\n",
    "        gba_adv = [[2*value-1 for value in group] for group in gba_acc]\n",
    "        gba_adv_group = [np.mean([value for value in group]) for group in gba_adv]\n",
    "\n",
    "    return alooa_adv_group, ga_adv_group, gba_adv_group\n",
    "\n",
    "\n",
    "def get_all_seeds(dataset_name, model_name, method, epsilon, other=True):\n",
    "    configs = get_config(dataset_name, model_name)\n",
    "\n",
    "    random_seeds = [\"_1\", \"_12\", \"_123\", \"_1234\", \"\"]\n",
    "\n",
    "    alooa_adv, ga_adv, gba_adv = [], [], []\n",
    "\n",
    "    for seed in random_seeds:\n",
    "        alooa_adv_group, ga_adv_group, gba_adv_group = get_one_seed(dataset_name, model_name, method, epsilon, other, seed, configs)\n",
    "        alooa_adv.append(alooa_adv_group)\n",
    "        ga_adv.append(ga_adv_group)\n",
    "        gba_adv.append(gba_adv_group)\n",
    "    \n",
    "    return np.array(alooa_adv), np.array(ga_adv), np.array(gba_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"raceface\"\n",
    "model_name = \"CNN\"\n",
    "method = \"regular\"\n",
    "epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alooa: 1.7464 $\\pm$ 0.1085\n"
     ]
    }
   ],
   "source": [
    "def get_delta_mean_std(adv):\n",
    "    delta = (np.max(adv, axis=1) - np.min(adv, axis=1)) * 100\n",
    "    mean_delta = np.mean(delta, axis=0)\n",
    "    std_delta = np.std(delta, axis=0)\n",
    "    return mean_delta, std_delta\n",
    "\n",
    "alooa_adv, ga_adv, gba_adv = get_all_seeds(dataset_name, model_name, method, epsilon, other=False)\n",
    "\n",
    "# ga_delta_mean, ga_delta_std = get_delta_mean_std(ga_adv)\n",
    "# print(rf\"ga: {ga_delta_mean:.4f} $\\pm$ {ga_delta_std:.4f}\")\n",
    "# gba_delta_mean, gba_delta_std = get_delta_mean_std(gba_adv)\n",
    "# print(rf\"gba: {gba_delta_mean:.4f} $\\pm$ {gba_delta_std:.4f}\")\n",
    "alooa_delta_mean, alooa_delta_std = get_delta_mean_std(alooa_adv)\n",
    "print(rf\"alooa: {alooa_delta_mean:.4f} $\\pm$ {alooa_delta_std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alooa_delta_mean, alooa_delta_std = get_delta_mean_std(alooa_adv)\n",
    "# print(rf\"alooa: {alooa_delta_mean:.4f} $\\pm$ {alooa_delta_std:.4f}\")\n",
    "# # 测试精度\n",
    "# configs = get_config(dataset_name, model_name)\n",
    "# path = f\"{configs[\"train\"][\"log_dir\"]}{model_name}/{method}/eps{epsilon}\"\n",
    "# with open(f\"{path}/models/models_metadata.json\", \"r\") as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# def get_mean_std(name):\n",
    "#     values = [entry[name] for entry in data.values()]\n",
    "#     mean_value = np.mean(values) \n",
    "#     std_value = np.std(values)\n",
    "#     return mean_value, std_value\n",
    "\n",
    "# # test_accs = [entry[\"test_acc\"] for entry in data.values()]\n",
    "# # mean_test_acc = np.mean(test_accs) * 100\n",
    "# # std_test_acc = np.std(test_accs)\n",
    "# # print(f\"Mean test accuracy: {mean_test_acc:.2f}\")\n",
    "# # print(f\"Standard deviation: {std_test_acc:.4f}\")\n",
    "\n",
    "# acc_mean, acc_std = get_mean_std(\"test_acc\")\n",
    "# print(rf\"test accuracy: {acc_mean:.4f} $\\pm$ {acc_std:.4f}\")\n",
    "# ap_mean, ap_std = get_mean_std(\"accuracy_parity\")\n",
    "# print(rf\"accuracy_parity: {ap_mean:.4f} $\\pm$ {ap_std:.4f}\")\n",
    "# dp_mean, dp_std = get_mean_std(\"demographic_parity\")\n",
    "# print(rf\"demographic_parity: {dp_mean:.4f} $\\pm$ {dp_std:.4f}\")\n",
    "# eop_mean, eop_std = get_mean_std(\"equal_opportunity\")\n",
    "# print(rf\"equal_opportunity: {eop_mean:.4f} $\\pm$ {eop_std:.4f}\")\n",
    "# eod_mean, eod_std = get_mean_std(\"equalized_odds\")\n",
    "# print(rf\"equalized_odds: {eod_mean:.4f} $\\pm$ {eod_std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# can be used for running multiple times pa-alooa, which have many group_adv_mean\n",
    "# \"\"\"\n",
    "# # Kruskal-Wallis \n",
    "# from scipy.stats import kruskal\n",
    "\n",
    "# stat, p = kruskal(*all_adv_acc)\n",
    "# print(f\"statistic: {stat}, p-value: {p}\")\n",
    "\n",
    "# # Mann-Whitney U \n",
    "# from scipy.stats import mannwhitneyu\n",
    "\n",
    "# stat, p = mannwhitneyu(all_adv_acc[1], all_adv_acc[5], alternative='two-sided')\n",
    "# print(f\"statistic: {stat}, p-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # configs = \"configs/utkface/utkface_regular.yaml\"\n",
    "# # configs = \"configs/raceface/raceface_regular.yaml\"\n",
    "# configs = \"configs/mnist/mnist_regular.yaml\"\n",
    "# # configs = \"configs/tabular/bank/bank_regular.yaml\"\n",
    "# with open(configs, \"rb\") as f:\n",
    "#     configs = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "# dataset_name = configs[\"data\"][\"dataset\"]\n",
    "# num_group = configs[\"train\"][\"num_groups\"]\n",
    "# model_name = \"CNN\"\n",
    "# epsilon = 10\n",
    "# method = \"regular\"\n",
    "# seed = \"\"\n",
    "\n",
    "\n",
    "# subdata_dir = f'{configs[\"run\"][\"log_dir\"]}{dataset_name}.pkl'\n",
    "# # exp_dir = f'{configs['run']['log_dir']}{model_name}/{method}/data/data_{data_idx}/eps{epsilon}'\n",
    "# exp_dir = f'{configs[\"run\"][\"log_dir\"]}{model_name}/{method}/eps{epsilon}{seed}'\n",
    "# log_dir = exp_dir\n",
    "# directories = {\n",
    "#     \"log_dir\": log_dir,\n",
    "#     \"report_dir\": f\"{log_dir}/report\",\n",
    "#     \"signal_dir\": f\"{log_dir}/signals\",\n",
    "# }\n",
    "\n",
    "# path = subdata_dir\n",
    "# if num_group == 2:\n",
    "#     path = f\"data/tabular/{dataset_name}.pkl\"\n",
    "# elif num_group == 5:\n",
    "#     path = f\"data/{dataset_name}.pkl\"\n",
    "# with open(path, \"rb\") as file:\n",
    "#     dataset = pickle.load(file)\n",
    "\n",
    "# path = directories[\"report_dir\"]\n",
    "# memberships = np.load(f\"{path}/memberships.npy\")\n",
    "# loss_scores = np.load(f\"{path}/loss_scores.npy\")\n",
    "\n",
    "\n",
    "# alooa_acc = exp_all_acc(f\"{directories['report_dir']}/loss\", loss_scores, memberships, dataset, num_group)\n",
    "# alooa_acc_group = [np.mean([value for value in group]) for group in alooa_acc]\n",
    "# alooa_adv = [[2*value-1 for value in group] for group in alooa_acc]\n",
    "# alooa_adv_group = [np.mean([value for value in group]) for group in alooa_adv]\n",
    "\n",
    "# # ga_acc = exp_all_avg_acc(f\"{directories['report_dir']}/loss\", loss_scores, memberships, dataset, num_group)\n",
    "# # ga_acc_group = [np.mean([value for value in group]) for group in ga_acc]\n",
    "# # ga_adv = [[2*value-1 for value in group] for group in ga_acc]\n",
    "# # ga_adv_group = [np.mean([value for value in group]) for group in ga_adv]\n",
    "\n",
    "# # gba_acc = exp_all_group_avg_acc(f\"{directories['report_dir']}/loss\", loss_scores, memberships, dataset, num_group)\n",
    "# # gba_acc_group = [np.mean([value for value in group]) for group in gba_acc]\n",
    "# # gba_adv = [[2*value-1 for value in group] for group in gba_acc]\n",
    "# # gba_adv_group = [np.mean([value for value in group]) for group in gba_adv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((max(alooa_adv_group) - min(alooa_adv_group)) *100)\n",
    "# print((max(ga_adv_group) - min(ga_adv_group)) *100)\n",
    "# print((max(gba_adv_group) - min(gba_adv_group)) *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(alooa_acc_group)\n",
    "# print(ga_acc_group)\n",
    "# print(gba_acc_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_mean = [np.mean([value for value in group]) for group in all_acc]\n",
    "# print(group_mean)\n",
    "# v = (max(group_mean) - min(group_mean)) *100\n",
    "# print(f\"{v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_adv_mean = [np.mean([value for value in group]) for group in all_adv_acc]\n",
    "# print(group_adv_mean)\n",
    "# v = (max(group_adv_mean) - min(group_adv_mean)) *100\n",
    "# print(f\"{v:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy_meter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
